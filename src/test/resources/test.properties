#
# Hadoop/Hive/Pig settings used for settings
#
# Note: the system properties are checked first - that is the command-line takes precedence (useful for CI) 

# Amazon EMR
# hive.port=10003
# hd.fs=s3n://work-emr/tmp
# hd.jt=localhost:20001
# hd.jt=10.80.205.79:9001

# Apache Whirr - EC2
# hd.fs=hdfs://xxx.amazonaws.com:8020
# hd.jt=xxx.amazonaws.com:8021

# Default - Vanilla Installs
#hd.fs=hdfs://${hadoop.host:localhost}:${hadoop.port:9000}

#
# Host settings
#

hostname=${hd.host|localhost}

## M&R
hadoop.fs.port=${fs.port|8020}
hadoop.jt.port=${jt.port|9000}

hadoop.fs=${hd.fs|hdfs://${hostname}:${hadoop.fs.port}}
hadoop.jt=${hd.jt|${hostname}:${hadoop.jt.port}}

## Hive
hive.host=${hd.hive.host|${hostname}}
hive.port=${hd.hive.port|10000}
hive.url=jdbc:hive://${hd.hive.host}:${hd.hive.port}

## HBase
hbase.host=${hd.hbase.host|${hostname}}
hbase.port=${hd.hbase.port|8070}

#
# Other settings
#

#path.cat=bin${file.separator}stream-bin${file.separator}cat
#path.wc=bin${file.separator}stream-bin${file.separator}wc
path.cat=cat
path.wc=wc

input.directory=logs
log.input=/logs/input/
log.output=/logs/output/

distcp.src=${hadoop.fs}/distcp/source.txt
distcp.dst=${hadoop.fs}/distcp/dst

cascade.sec=/test/cascading/loganalysis/sec
cascade.min=/test/cascading/loganalysis/min